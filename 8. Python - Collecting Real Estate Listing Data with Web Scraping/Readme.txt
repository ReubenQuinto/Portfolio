Objective: 
	- This was a University of California, Irvine project. 
	- The objective was to create a database of real estate listings in Irvine California. 
	- That database was utilized by another modeler on the team.


The solution: 
	- I created a web scraper on Trulia, which is a real estate listing website. 
	- I collected: year built, city, neighborhood, sqft, bedrooms, bathrooms, and price. 
	- The output was a csv file. 
	- I deployed the scraper on three laptops and 5 different servers. 
	- The idea was to "scrape as you sleep."

Key Takeaways: 
	- One of the biggest challenges was at some point the scraper would run into Google's CAPTCHA. 
	- My solution was to create sleep timers in-between scraping sessions to simulate human activity.